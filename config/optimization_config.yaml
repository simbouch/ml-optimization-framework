# Optimization Configuration
# This file defines the optimization settings for different models and scenarios

# Default Study Configuration
default_study_config:
  study_name: "ml_optimization_study"
  direction: "maximize"
  storage: "sqlite:///optuna_study.db"
  load_if_exists: true
  
  sampler_config:
    name: "tpe"
    params:
      seed: 42
      n_startup_trials: 10
      n_ei_candidates: 24
      multivariate: true
      warn_independent_sampling: true
  
  pruner_config:
    name: "median"
    params:
      n_startup_trials: 5
      n_warmup_steps: 5
      interval_steps: 1

# Model-Specific Study Configurations
study_configs:
  
  random_forest:
    study_name: "random_forest_optimization"
    direction: "maximize"
    storage: "sqlite:///rf_study.db"
    load_if_exists: true
    
    sampler_config:
      name: "tpe"
      params:
        seed: 42
        n_startup_trials: 10
        multivariate: true
    
    pruner_config:
      name: "median"
      params:
        n_startup_trials: 5
        n_warmup_steps: 3
        interval_steps: 1
  
  xgboost:
    study_name: "xgboost_optimization"
    direction: "maximize"
    storage: "sqlite:///xgb_study.db"
    load_if_exists: true
    
    sampler_config:
      name: "tpe"
      params:
        seed: 42
        n_startup_trials: 15
        multivariate: true
    
    pruner_config:
      name: "median"
      params:
        n_startup_trials: 10
        n_warmup_steps: 10
        interval_steps: 1
  
  lightgbm:
    study_name: "lightgbm_optimization"
    direction: "maximize"
    storage: "sqlite:///lgb_study.db"
    load_if_exists: true
    
    sampler_config:
      name: "tpe"
      params:
        seed: 42
        n_startup_trials: 15
        multivariate: true
    
    pruner_config:
      name: "successive_halving"
      params:
        min_resource: 1
        reduction_factor: 4
        min_early_stopping_rate: 0

# Multi-Objective Optimization Settings
multi_objective_configs:
  
  accuracy_vs_time:
    study_name: "accuracy_time_optimization"
    directions: ["maximize", "minimize"]
    objectives: ["accuracy", "training_time"]
    storage: "sqlite:///multi_obj_study.db"
    
    sampler_config:
      name: "tpe"
      params:
        seed: 42
        n_startup_trials: 20
  
  accuracy_vs_complexity:
    study_name: "accuracy_complexity_optimization"
    directions: ["maximize", "minimize"]
    objectives: ["accuracy", "model_complexity"]
    storage: "sqlite:///acc_complex_study.db"
    
    sampler_config:
      name: "tpe"
      params:
        seed: 42
        n_startup_trials: 20

# Sampler Configurations
sampler_configs:
  
  tpe_default:
    name: "tpe"
    params:
      seed: 42
      n_startup_trials: 10
      n_ei_candidates: 24
      multivariate: true
      warn_independent_sampling: true
  
  tpe_aggressive:
    name: "tpe"
    params:
      seed: 42
      n_startup_trials: 5
      n_ei_candidates: 50
      multivariate: true
      gamma: 0.15
  
  cmaes_default:
    name: "cmaes"
    params:
      seed: 42
      n_startup_trials: 10
      restart_strategy: "ipop"
  
  random_default:
    name: "random"
    params:
      seed: 42
  
  grid_search:
    name: "grid"
    params:
      search_space: null  # Will be defined programmatically

# Pruner Configurations
pruner_configs:
  
  median_conservative:
    name: "median"
    params:
      n_startup_trials: 10
      n_warmup_steps: 10
      interval_steps: 1
  
  median_aggressive:
    name: "median"
    params:
      n_startup_trials: 5
      n_warmup_steps: 3
      interval_steps: 1
  
  successive_halving_default:
    name: "successive_halving"
    params:
      min_resource: 1
      reduction_factor: 4
      min_early_stopping_rate: 0
  
  hyperband_default:
    name: "hyperband"
    params:
      min_resource: 1
      max_resource: "auto"
      reduction_factor: 3

# Optimization Scenarios
optimization_scenarios:
  
  quick_prototype:
    description: "Fast optimization for prototyping"
    n_trials: 50
    cv_folds: 3
    timeout: 300  # 5 minutes
    
    sampler_config:
      name: "random"
      params:
        seed: 42
    
    pruner_config:
      name: "median"
      params:
        n_startup_trials: 3
        n_warmup_steps: 2
  
  standard_optimization:
    description: "Standard optimization for most use cases"
    n_trials: 200
    cv_folds: 5
    timeout: 3600  # 1 hour
    
    sampler_config:
      name: "tpe"
      params:
        seed: 42
        n_startup_trials: 10
        multivariate: true
    
    pruner_config:
      name: "median"
      params:
        n_startup_trials: 5
        n_warmup_steps: 5
  
  thorough_optimization:
    description: "Comprehensive optimization for production models"
    n_trials: 500
    cv_folds: 10
    timeout: 7200  # 2 hours
    
    sampler_config:
      name: "tpe"
      params:
        seed: 42
        n_startup_trials: 20
        multivariate: true
        n_ei_candidates: 50
    
    pruner_config:
      name: "successive_halving"
      params:
        min_resource: 1
        reduction_factor: 4

# Callback Configurations
callback_configs:
  
  basic_logging:
    log_best: true
    log_progress: true
    early_stopping: false
    file_logging: false
    metrics_tracking: false
    
    best_log_frequency: 10
    progress_log_frequency: 25
    verbose: true
  
  comprehensive_logging:
    log_best: true
    log_progress: true
    early_stopping: true
    file_logging: true
    metrics_tracking: true
    
    best_log_frequency: 5
    progress_log_frequency: 20
    patience: 50
    min_improvement: 1e-4
    log_filepath: "optimization_log.json"
    log_format: "json"
    tracked_metrics: ["accuracy", "f1_score", "training_time"]
    verbose: true
  
  production_monitoring:
    log_best: true
    log_progress: true
    early_stopping: true
    file_logging: true
    metrics_tracking: true
    
    best_log_frequency: 1
    progress_log_frequency: 10
    patience: 30
    min_improvement: 1e-5
    log_filepath: "production_optimization.json"
    log_format: "json"
    tracked_metrics: ["accuracy", "f1_score", "precision", "recall", "roc_auc", "training_time"]
    verbose: false

# Data Pipeline Settings
data_pipeline_config:
  random_state: 42
  test_size: 0.2
  val_size: 0.2
  stratify: true
  
  preprocessing:
    categorical_encoding: "ordinal"  # or "onehot"
    numerical_scaling: "standard"    # or "robust", "minmax"
    handle_missing: true
    
  validation:
    check_data_quality: true
    min_samples_per_class: 10
    max_missing_ratio: 0.1

# Evaluation Settings
evaluation_config:
  
  metrics:
    primary: "accuracy"
    secondary: ["f1_score", "precision", "recall", "roc_auc"]
    
  cross_validation:
    n_splits: 5
    shuffle: true
    stratify: true
    
  test_evaluation:
    calculate_confidence_intervals: true
    bootstrap_samples: 1000
    confidence_level: 0.95

# Visualization Settings
visualization_config:
  
  default_style: "seaborn"
  figure_size: [12, 8]
  dpi: 300
  
  plots:
    optimization_history:
      show_best: true
      interactive: true
      
    parameter_importance:
      top_k: 10
      interactive: true
      
    parallel_coordinates:
      max_params: 8
      interactive: true
      
    slice_plots:
      max_params: 6
      interactive: true
      
    edf_comparison:
      interactive: true
  
  dashboard:
    auto_refresh: false
    theme: "plotly_white"
    save_html: true

# Resource Management
resource_config:
  
  parallel_jobs: -1  # Use all available cores
  memory_limit: "8GB"
  gpu_acceleration: false
  
  optimization_timeout: 7200  # 2 hours
  trial_timeout: 300          # 5 minutes per trial
  
  storage_cleanup:
    auto_cleanup: false
    max_studies: 10
    max_age_days: 30

# Logging Configuration
logging_config:
  
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
  handlers:
    console:
      enabled: true
      level: "INFO"
      
    file:
      enabled: true
      level: "DEBUG"
      filename: "optimization.log"
      max_bytes: 10485760  # 10MB
      backup_count: 5
      
    optuna_dashboard:
      enabled: true
      level: "WARNING"
