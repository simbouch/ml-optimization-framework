# Optuna : L'outil qui va changer votre fa√ßon de faire du ML

Salut l'√©quipe ! Alors, Optuna... c'est quoi exactement ? Je vais vous expliquer √ßa simplement mais de fa√ßon compl√®te, parce que c'est vraiment un outil g√©nial que j'ai d√©couvert et que je veux partager avec vous.

## Qu'est-ce qu'Optuna ?

**D√©finition officielle :** Optuna est un framework open-source d'optimisation automatique d'hyperparam√®tres (automatic hyperparameter optimization framework), sp√©cialement con√ßu pour le machine learning et le deep learning.

**En gros :** Imaginez que vous avez un mod√®le Random Forest et que vous devez choisir :
- Combien d'arbres ? (n_estimators)
- Quelle profondeur ? (max_depth)
- Quel crit√®re de division ? (criterion)
- Et plein d'autres param√®tres...

Normalement, vous testez √† la main : 50 arbres, puis 100, puis 200... C'est long et franchement chiant. On a tous fait √ßa, non ?

**Optuna fait √ßa automatiquement.** Vous lui dites "trouve-moi les meilleurs param√®tres" et il le fait. Point. C'est aussi simple que √ßa.

## Un peu d'histoire pour la culture

**Cr√©√© par :** Preferred Networks (PFN) - une startup japonaise sp√©cialis√©e en deep learning
**Premi√®re release :** D√©cembre 2018 (version beta)
**Open-source depuis :** 2018
**Cr√©ateur principal :** Takuya Akiba et son √©quipe chez PFN
**Utilis√© par :** Des milliers d'entreprises dans le monde, y compris chez PFN pour leurs comp√©titions (ils ont fini 2√®me √† l'Open Images Challenge 2018)

**Petit d√©tail int√©ressant :** PFN a aussi cr√©√© Chainer, un des premiers frameworks Define-by-Run (avant PyTorch !). Optuna applique la m√™me philosophie Define-by-Run √† l'optimisation d'hyperparam√®tres. C'est coh√©rent dans leur approche.

**Frameworks support√©s :**
- **Machine Learning classique :** Scikit-learn, XGBoost, LightGBM, CatBoost
- **Deep Learning :** TensorFlow, Keras, PyTorch, Chainer, JAX
- **Autres :** M√™me des trucs non-ML si vous voulez optimiser des param√®tres

**Exemples concrets :**
```python
# ML classique
model = RandomForestClassifier(n_estimators=trial.suggest_int('n_estimators', 10, 200))

# Deep Learning
model = tf.keras.Sequential([
    tf.keras.layers.Dense(trial.suggest_int('units', 32, 512), activation='relu')
])
```

## Le probl√®me qu'on a tous

Quand je fais du ML, j'ai toujours ce probl√®me :

```python
model = RandomForestClassifier(
    n_estimators=???,      # 10 ? 50 ? 100 ? 500 ?
    max_depth=???,         # 5 ? 10 ? 20 ? illimit√©e ?
    min_samples_split=???, # 2 ? 5 ? 10 ? 20 ?
    # ... et plein d'autres param√®tres
)
```

Vous voyez le probl√®me ? Il y a des MILLIARDS de combinaisons possibles. M√™me en testant une combinaison par seconde, il faudrait des ann√©es pour tout essayer.

## Ce qu'on faisait avant (et pourquoi c'est nul)

### M√©thode 1 : Les valeurs par d√©faut
```python
model = RandomForestClassifier()  # On croise les doigts
```
**Probl√®me :** √áa marche rarement bien sur vos donn√©es.

### M√©thode 2 : Essai-erreur √† la main
```python
# On teste √† la main comme des sauvages
model1 = RandomForestClassifier(n_estimators=50)
model2 = RandomForestClassifier(n_estimators=100)
# ... 3 heures plus tard, on a test√© 5 combinaisons
```
**Probl√®me :** C'est long, pas syst√©matique, et on rate s√ªrement le meilleur.

### M√©thode 3 : Grid Search
```python
param_grid = {
    'n_estimators': [10, 50, 100, 200],
    'max_depth': [5, 10, 20, None]
}
# Teste TOUTES les combinaisons : 4 √ó 4 = 16 essais
```
**Probl√®me :** √áa explose exponentiellement. Avec 5 param√®tres, vous avez d√©j√† des milliers de combinaisons.

## Pourquoi Optuna c'est g√©nial

### 1. C'est BEAUCOUP plus rapide

**Avant (Grid Search) :**
- Je teste 1000 combinaisons
- √áa prend des jours
- R√©sultats moyens

**Avec Optuna :**
- Il teste intelligemment 50-100 combinaisons
- √áa prend quelques heures
- R√©sultats excellents
- **10 √† 100 fois plus rapide !**

### 2. Il apprend de ses erreurs

Contrairement au Random Search qui teste au hasard, Optuna est intelligent :
- Il regarde les r√©sultats pr√©c√©dents
- Il comprend quels param√®tres marchent bien
- Il concentre ses efforts sur les zones prometteuses

C'est comme avoir un assistant qui apprend de vos exp√©riences.

### 3. C'est super simple √† utiliser

Regardez, voici tout le code dont vous avez besoin :

```python
import optuna

def objective(trial):
    # Optuna sugg√®re des param√®tres
    n_estimators = trial.suggest_int('n_estimators', 10, 200)
    max_depth = trial.suggest_int('max_depth', 2, 32)

    # Vous testez votre mod√®le
    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)
    score = cross_val_score(model, X, y, cv=3).mean()

    return score

# Vous lancez l'optimisation
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# Vous r√©cup√©rez les meilleurs param√®tres
print(f"Meilleurs param√®tres : {study.best_params}")
```

C'est tout ! Optuna fait le reste.

## Fonctionnalit√©s avanc√©es pour les pros

### Distributed Optimization (Optimisation Distribu√©e)

**Le principe :** Vous pouvez lancer plusieurs workers en parall√®le pour acc√©l√©rer l'optimisation. C'est super pratique quand vous avez plusieurs machines ou plusieurs GPUs.

```python
# Worker 1
study = optuna.load_study(study_name="shared_study", storage="sqlite:///shared.db")
study.optimize(objective, n_trials=50)

# Worker 2 (en parall√®le sur une autre machine)
study = optuna.load_study(study_name="shared_study", storage="sqlite:///shared.db")
study.optimize(objective, n_trials=50)
```

**Les avantages :** Acc√©l√©ration quasi-lin√©aire avec le nombre de workers, et le partage des r√©sultats se fait automatiquement via la base de donn√©es. Pas besoin de s'emb√™ter avec la synchronisation.

### Callbacks et Monitoring

**Le principe :** Vous pouvez ex√©cuter du code personnalis√© √† chaque trial. Tr√®s pratique pour logger, sauvegarder, ou arr√™ter l'optimisation selon vos crit√®res.

```python
def logging_callback(study, trial):
    print(f"Trial {trial.number}: {trial.value}")
    if trial.value > 0.95:
        print("Excellent score atteint ! On peut s'arr√™ter l√†.")
        study.stop()

study.optimize(objective, n_trials=100, callbacks=[logging_callback])
```

### Dynamic Search Space (Espace de Recherche Dynamique)

**Le principe :** L'espace de recherche peut changer selon les param√®tres choisis. Par exemple, si vous choisissez Random Forest, vous aurez certains param√®tres, mais si vous choisissez SVM, vous en aurez d'autres.

```python
def objective(trial):
    classifier = trial.suggest_categorical('classifier', ['RF', 'SVM', 'NN'])

    if classifier == 'RF':
        n_estimators = trial.suggest_int('n_estimators', 10, 200)
        max_depth = trial.suggest_int('max_depth', 3, 20)
        return train_random_forest(n_estimators, max_depth)
    elif classifier == 'SVM':
        C = trial.suggest_float('C', 1e-3, 1e3, log=True)
        gamma = trial.suggest_float('gamma', 1e-4, 1e-1, log=True)
        return train_svm(C, gamma)
    else:  # Neural Network
        layers = trial.suggest_int('layers', 1, 5)
        units = trial.suggest_int('units', 32, 512)
        dropout = trial.suggest_float('dropout', 0.1, 0.5)
        return train_nn(layers, units, dropout)
```

### Int√©grations avec d'autres outils

**MLflow Integration :**
Si vous utilisez MLflow pour tracker vos exp√©riences, Optuna s'int√®gre parfaitement :

```python
import optuna.integration.mlflow as optuna_mlflow

study = optuna_mlflow.create_study(
    storage="sqlite:///optuna.db",
    study_name="mlflow_study"
)
```

**Weights & Biases (wandb) :**
Pareil pour wandb, tr√®s populaire dans la communaut√© deep learning :

```python
import optuna.integration.wandb as optuna_wandb

wandbc = optuna_wandb.WeightsAndBiasesCallback(project="optuna-project")
study.optimize(objective, n_trials=100, callbacks=[wandbc])
```

## Les algorithmes derri√®re Optuna (pour les curieux)

### TPE (Tree-structured Parzen Estimator)

**D√©finition technique :** TPE est un algorithme d'optimisation bay√©sienne qui mod√©lise la distribution des hyperparam√®tres conditionnellement aux performances observ√©es, en utilisant des estimateurs de Parzen structur√©s en arbre.

**En gros :** TPE apprend de vos essais pr√©c√©dents pour devenir de plus en plus intelligent. C'est l'algorithme par d√©faut d'Optuna et franchement, il est tr√®s bon.

**Comment √ßa marche (algorithme simplifi√©) :**
1. **Divise les trials** en deux groupes :
   - **Good trials** : Top 20% des meilleurs r√©sultats
   - **Bad trials** : Bottom 80% des moins bons r√©sultats

2. **Mod√©lise deux distributions probabilistes** :
   - **l(x)** = P(hyperparam√®tres | bon r√©sultat)
   - **g(x)** = P(hyperparam√®tres | mauvais r√©sultat)

3. **Choisit les param√®tres** qui maximisent le ratio **l(x)/g(x)**
   - Plus ce ratio est √©lev√©, plus les param√®tres sont prometteurs

4. **Expected Improvement (EI)** : Utilise une acquisition function pour √©quilibrer exploration vs exploitation

**L'avantage :** Plus il y a d'essais, plus TPE devient intelligent. C'est de l'apprentissage automatique pour optimiser l'apprentissage automatique ! Assez m√©ta comme concept, non ?

### Bayesian Optimization (Optimisation Bay√©sienne)

**D√©finition technique :** L'optimisation bay√©sienne est une approche probabiliste pour optimiser des fonctions co√ªteuses √† √©valuer, en utilisant un mod√®le de substitution (surrogate model) et une fonction d'acquisition (acquisition function).

**Le principe :** Optuna utilise l'optimisation bay√©sienne pour √©quilibrer intelligemment exploration et exploitation. C'est la base th√©orique derri√®re TPE.

- **Exploration** : Tester des zones inconnues de l'espace des param√®tres (pour d√©couvrir de nouvelles possibilit√©s)
- **Exploitation** : Se concentrer sur les zones prometteuses d√©j√† d√©couvertes (pour optimiser ce qu'on sait d√©j√†)

**Acquisition Function :** C'est une fonction math√©matique qui d√©cide o√π chercher ensuite en maximisant l'information attendue. En gros, elle r√©pond √† la question "o√π est-ce que je devrais tester mes prochains param√®tres ?".

**Types d'acquisition functions :**
- **Expected Improvement (EI)** : Am√©lioration esp√©r√©e par rapport au meilleur r√©sultat actuel
- **Upper Confidence Bound (UCB)** : Borne sup√©rieure de confiance
- **Probability of Improvement (PI)** : Probabilit√© d'am√©lioration

**Pourquoi c'est g√©nial :** Au lieu de tester au hasard, Optuna "r√©fl√©chit" avant chaque essai ! Il utilise toute l'information des essais pr√©c√©dents pour prendre des d√©cisions intelligentes.

### Multi-objective Optimization (Optimisation Multi-Objectifs)

**D√©finition technique :** L'optimisation multi-objectifs consiste √† optimiser simultan√©ment plusieurs fonctions objectifs potentiellement conflictuelles, en recherchant l'ensemble des solutions Pareto-optimales.

**Le principe :** Optimiser plusieurs objectifs simultan√©ment. Par exemple, vous voulez un mod√®le pr√©cis ET rapide, ou un mod√®le performant ET qui consomme peu de m√©moire.

**Pareto Front (Front de Pareto) :** C'est l'ensemble des solutions o√π on ne peut am√©liorer un objectif sans d√©grader au moins un autre objectif. Ces solutions sont dites "non-domin√©es" (non-dominated). En gros, ce sont toutes les solutions "int√©ressantes".

**Exemple concret :**
```python
def objective(trial):
    # Param√®tres du mod√®le
    n_estimators = trial.suggest_int('n_estimators', 10, 200)
    max_depth = trial.suggest_int('max_depth', 2, 20)

    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)
    model.fit(X_train, y_train)

    # Deux objectifs conflictuels
    accuracy = model.score(X_test, y_test)           # On veut maximiser
    model_size = n_estimators * max_depth            # On veut minimiser

    return accuracy, model_size

# Cr√©er une √©tude multi-objectifs
study = optuna.create_study(directions=['maximize', 'minimize'])
study.optimize(objective, n_trials=100)

# R√©cup√©rer le front de Pareto
pareto_front = study.best_trials  # Toutes les solutions non-domin√©es
```

**Applications typiques :**
- **Accuracy vs Speed** : Mod√®le pr√©cis mais rapide
- **Performance vs Memory** : Bon score avec peu de RAM
- **Precision vs Recall** : √âquilibrer les deux m√©triques
- **Accuracy vs Model Size** : Performance vs complexit√©

### 4. Le dashboard est magnifique

Optuna vous donne un dashboard web super clean o√π vous pouvez :
- Voir comment l'optimisation progresse
- Comprendre quels param√®tres sont les plus importants
- Analyser les relations entre param√®tres
- Comparer diff√©rentes exp√©riences

C'est vraiment bien fait, vous allez voir.

### 5. Plein de fonctionnalit√©s cool

- **Pruning** : Il arr√™te les essais pourris avant la fin (gain de temps √©norme)
- **Multi-objectifs** : Vous pouvez optimiser pr√©cision ET vitesse en m√™me temps
- **Parall√©lisation** : Il peut lancer plusieurs essais en parall√®le
- **Sauvegarde auto** : Tout est sauv√©, vous pouvez reprendre plus tard

## Les concepts de base (important √† comprendre)

### Study (√âtude)

**D√©finition technique :** Une study est un objet qui encapsule une exp√©rience d'optimisation compl√®te, incluant l'historique des trials, la configuration du sampler/pruner, et les m√©tadonn√©es.

**En pratique :** C'est votre exp√©rience d'optimisation compl√®te. Vous cr√©ez une study pour chaque probl√®me que vous voulez r√©soudre.

```python
study = optuna.create_study(
    study_name="mon_experience_RF",           # Nom de l'√©tude
    direction='maximize',                     # maximize ou minimize
    sampler=optuna.samplers.TPESampler(),    # Strat√©gie d'optimisation
    pruner=optuna.pruners.MedianPruner()     # Arr√™t pr√©coce (optionnel)
)
```

### Trial (Essai)

**D√©finition technique :** Un trial repr√©sente une √©valuation unique de la fonction objectif avec un ensemble sp√©cifique d'hyperparam√®tres sugg√©r√©s par le sampler.

**En pratique :** Chaque fois qu'Optuna teste une combinaison de param√®tres, c'est un trial. Simple comme √ßa.

```python
def objective(trial):
    # Optuna va appeler cette fonction plein de fois
    # Chaque appel = 1 trial avec des param√®tres diff√©rents
    x = trial.suggest_float('x', -10, 10)
    return (x - 2) ** 2  # Fonction √† optimiser
```

**√âtats possibles d'un trial :**
- **COMPLETE** : Trial termin√© avec succ√®s
- **PRUNED** : Trial arr√™t√© pr√©matur√©ment (pruning)
- **FAIL** : Trial √©chou√© (exception)
- **RUNNING** : Trial en cours d'ex√©cution

### **3. Objective Function (Fonction Objectif)**

**D√©finition technique :** La fonction objectif est une fonction math√©matique qui prend en entr√©e un ensemble d'hyperparam√®tres et retourne une m√©trique de performance √† optimiser.

**En pratique :** C'est la fonction qu'Optuna va essayer d'optimiser. Vous lui dites "voici comment √©valuer une combinaison de param√®tres".

```python
def objective(trial):
    # 1. Optuna sugg√®re des param√®tres
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 10, 200),
        'max_depth': trial.suggest_int('max_depth', 2, 32)
    }

    # 2. Vous entra√Ænez votre mod√®le avec ces param√®tres
    model = RandomForestClassifier(**params)
    model.fit(X_train, y_train)

    # 3. Vous √©valuez et retournez le score
    score = model.score(X_test, y_test)
    return score  # Optuna va essayer de maximiser √ßa
```

**Points importants :**
- La fonction doit √™tre **d√©terministe** (m√™me entr√©e = m√™me sortie)
- Elle peut retourner une ou plusieurs valeurs (multi-objectifs)
- Plus la fonction est rapide, plus l'optimisation est efficace

### **4. Sampler (√âchantillonneur)**

**D√©finition technique :** Un sampler est un algorithme qui d√©termine comment explorer l'espace des hyperparam√®tres pour trouver l'optimum global de mani√®re efficace.

**En pratique :** C'est la strat√©gie qu'Optuna utilise pour choisir intelligemment les param√®tres √† tester.

```python
# TPE (Tree-structured Parzen Estimator) - Le plus intelligent
study = optuna.create_study(sampler=optuna.samplers.TPESampler())

# Random Sampler - Choix al√©atoire (baseline)
study = optuna.create_study(sampler=optuna.samplers.RandomSampler())

# Grid Sampler - Teste toutes les combinaisons
study = optuna.create_study(sampler=optuna.samplers.GridSampler(...))

# CMA-ES - Optimisation √©volutionnaire
study = optuna.create_study(sampler=optuna.samplers.CmaEsSampler())
```

**Comparaison d√©taill√©e des samplers :**

**TPE (Tree-structured Parzen Estimator) - LE CHAMPION**
- **Principe :** Optimisation bay√©sienne avec mod√®les de Parzen
- **Avantages :** Apprend des essais pr√©c√©dents, tr√®s efficace, convergence rapide
- **Inconv√©nients :** Peut √™tre lent au d√©but (warmup period)
- **Quand l'utiliser :** TOUJOURS (sauf cas sp√©ciaux). C'est le d√©faut d'Optuna pour une bonne raison.

**Random Sampler - LA BASELINE**
- **Principe :** √âchantillonnage al√©atoire uniforme dans l'espace de recherche
- **Avantages :** Simple, rapide, bon pour d√©buter, pas de biais
- **Inconv√©nients :** N'apprend pas, inefficace sur de gros espaces
- **Quand l'utiliser :** Baseline de comparaison, espaces tr√®s simples

**Grid Sampler - L'EXHAUSTIF**
- **Principe :** Teste toutes les combinaisons possibles (recherche exhaustive)
- **Avantages :** Garantit de trouver l'optimum, reproductible
- **Inconv√©nients :** Explosion combinatoire, tr√®s lent
- **Quand l'utiliser :** Peu de param√®tres (<5), espaces discrets petits

**CMA-ES (Covariance Matrix Adaptation Evolution Strategy) - L'√âVOLUTIONNAIRE**
- **Principe :** Algorithme √©volutionnaire qui adapte sa matrice de covariance
- **Avantages :** Excellent pour espaces continus, g√®re bien les corr√©lations
- **Inconv√©nients :** Lent, pas optimal pour espaces discrets/cat√©goriels
- **Quand l'utiliser :** Deep learning, espaces continus complexes, corr√©lations entre param√®tres

**Nouveaux samplers avanc√©s :**
- **GPSampler** : Gaussian Process-based (Optuna 4.4+)
- **NSGAIISampler** : Multi-objectifs avec NSGA-II
- **QMCSampler** : Quasi-Monte Carlo sampling

### **5. Pruner (√âlagueur)**

**D√©finition technique :** Un pruner analyse les r√©sultats interm√©diaires d'un trial en cours et d√©cide s'il faut l'arr√™ter pr√©matur√©ment bas√© sur des crit√®res statistiques.

**En pratique :** Il arr√™te les essais qui vont mal avant la fin. √áa √©conomise √©norm√©ment de temps (jusqu'√† 70% !).

```python
# MedianPruner - Arr√™te si en dessous de la m√©diane
study = optuna.create_study(
    pruner=optuna.pruners.MedianPruner(
        n_startup_trials=5,    # Attendre 5 trials avant de commencer
        n_warmup_steps=10      # Attendre 10 √©tapes avant de pruner
    )
)

def objective(trial):
    model = create_model(trial)

    for epoch in range(100):
        train_loss = train_one_epoch(model)
        val_loss = validate(model)

        # Rapporter le score interm√©diaire √† Optuna
        trial.report(val_loss, epoch)

        # Le pruner d√©cide s'il faut arr√™ter
        if trial.should_prune():
            raise optuna.TrialPruned()  # Arr√™t pr√©coce

    return final_val_loss
```

**Types de pruners d√©taill√©s :**

**MedianPruner - LE CLASSIQUE**
- **Principe :** Arr√™te un trial si sa performance interm√©diaire est en dessous de la m√©diane des trials pr√©c√©dents
- **Param√®tres cl√©s :**
  - `n_startup_trials=5` : Nombre de trials avant activation
  - `n_warmup_steps=10` : √âtapes d'√©chauffement avant pruning
- **Avantages :** Simple, efficace, peu de param√®tres √† r√©gler
- **Quand l'utiliser :** Cas g√©n√©ral, deep learning, gradient boosting. C'est mon choix par d√©faut.

**PercentilePruner - LE PERSONNALISABLE**
- **Principe :** Arr√™te si en dessous d'un percentile sp√©cifique (ex: 25√®me percentile)
- **Param√®tres :** `percentile=25.0` (plus agressif si plus √©lev√©)
- **Avantages :** Contr√¥le fin du niveau d'agressivit√©
- **Quand l'utiliser :** Quand vous voulez ajuster la s√©v√©rit√© du pruning

**SuccessiveHalvingPruner - L'√âLIMINATEUR**
- **Principe :** √âlimine progressivement la moiti√© des trials les moins performants √† chaque √©tape
- **Inspiration :** Algorithme Successive Halving de Jamieson & Talwalkar
- **Avantages :** Tr√®s efficace, √©conomise beaucoup de temps
- **Inconv√©nients :** Peut √™tre trop agressif parfois

**HyperbandPruner - LE SOPHISTIQU√â**
- **Principe :** Combine Successive Halving avec diff√©rents budgets (version avanc√©e)
- **Inspiration :** Algorithme Hyperband de Li et al.
- **Avantages :** Optimal th√©oriquement, tr√®s efficace
- **Inconv√©nients :** Plus complexe √† param√©trer

**PatientPruner - LE PATIENT**
- **Principe :** Arr√™te apr√®s un nombre d'√©tapes sans am√©lioration
- **Param√®tres :** `patience=10` (nombre d'√©tapes √† attendre)
- **Avantages :** √âvite l'arr√™t pr√©matur√© de trials prometteurs
- **Quand l'utiliser :** Fonctions objectifs bruyantes, convergence lente

---

## ‚öôÔ∏è Comment Fonctionne Optuna ?

### **Processus d'Optimisation**

```
1. Initialisation
   ‚Üì
2. Sugg√©rer des param√®tres (Sampler)
   ‚Üì
3. √âvaluer la fonction objectif
   ‚Üì
4. Enregistrer le r√©sultat
   ‚Üì
5. Apprendre des r√©sultats pr√©c√©dents
   ‚Üì
6. R√©p√©ter 2-5 jusqu'√† n_trials
   ‚Üì
7. Retourner les meilleurs param√®tres
```

### **Algorithme TPE (Simplifi√©)**

```
Pour chaque nouveau trial :
1. Diviser les trials pr√©c√©dents en 2 groupes :
   - Bons r√©sultats (top 20%)
   - Mauvais r√©sultats (bottom 80%)

2. Mod√©liser la distribution des param√®tres :
   - P(params | bon r√©sultat)
   - P(params | mauvais r√©sultat)

3. Choisir les param√®tres qui maximisent :
   P(bon | params) / P(mauvais | params)

4. Tester ces param√®tres

5. Mettre √† jour les mod√®les
```

**R√©sultat :** Concentration progressive sur les zones prometteuses

---

## üéØ Fonctionnalit√©s Principales

### **1. Types de Param√®tres Support√©s**

```python
def objective(trial):
    # Entier
    n_estimators = trial.suggest_int('n_estimators', 10, 200)
    
    # Flottant
    learning_rate = trial.suggest_float('lr', 1e-5, 1e-1, log=True)
    
    # Cat√©goriel
    optimizer = trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop'])
    
    # Discret
    dropout = trial.suggest_float('dropout', 0.1, 0.5, step=0.1)
    
    return score
```

### **2. Optimisation Multi-objectifs**

```python
def objective(trial):
    params = {...}
    model = train_model(params)
    
    accuracy = evaluate_accuracy(model)
    complexity = count_parameters(model)
    
    # Retourner plusieurs objectifs
    return accuracy, complexity

# Cr√©er une √©tude multi-objectifs
study = optuna.create_study(
    directions=['maximize', 'minimize']  # accuracy ‚Üë, complexity ‚Üì
)
```

### **3. Pruning (Arr√™t Pr√©coce)**

```python
def objective(trial):
    model = create_model(trial)
    
    for epoch in range(100):
        train_loss = train_one_epoch(model)
        val_loss = validate(model)
        
        # Rapporter le score interm√©diaire
        trial.report(val_loss, epoch)
        
        # Arr√™ter si non prometteur
        if trial.should_prune():
            raise optuna.TrialPruned()
    
    return final_val_loss
```

**Avantage :** √âconomise jusqu'√† 50-70% du temps de calcul

### **4. Callbacks et Monitoring**

```python
def callback(study, trial):
    if trial.value < best_threshold:
        print(f"Nouveau meilleur score : {trial.value}")

study.optimize(objective, n_trials=100, callbacks=[callback])
```

---

## üíª Exemple Simple

### **Probl√®me : Optimiser un Random Forest**

```python
import optuna
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.datasets import load_iris

# Charger les donn√©es
X, y = load_iris(return_X_y=True)

# D√©finir la fonction objectif
def objective(trial):
    # Sugg√©rer des hyperparam√®tres
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 10, 200),
        'max_depth': trial.suggest_int('max_depth', 2, 32),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
    }
    
    # Cr√©er et √©valuer le mod√®le
    model = RandomForestClassifier(**params, random_state=42)
    score = cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()
    
    return score

# Cr√©er et lancer l'√©tude
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# Afficher les r√©sultats
print("Meilleurs param√®tres :", study.best_params)
print("Meilleur score :", study.best_value)
```

**R√©sultat :**
```
Meilleurs param√®tres : {
    'n_estimators': 156,
    'max_depth': 8,
    'min_samples_split': 2,
    'min_samples_leaf': 1
}
Meilleur score : 0.973
```

---

## üåç Cas d'Usage R√©els

### **1. Classification d'Images**
- Optimiser les hyperparam√®tres de CNN
- Trouver le meilleur learning rate
- Optimiser l'architecture du r√©seau

### **2. Traitement du Langage Naturel**
- Optimiser les mod√®les de transformers
- Trouver la meilleure taille de vocabulaire
- Optimiser les param√®tres d'embedding

### **3. S√©ries Temporelles**
- Optimiser les mod√®les LSTM/GRU
- Trouver la meilleure fen√™tre temporelle
- Optimiser les param√®tres de pr√©diction

### **4. Syst√®mes de Recommandation**
- Optimiser les algorithmes de filtrage collaboratif
- Trouver les meilleurs param√®tres de factorisation matricielle
- Optimiser les mod√®les hybrides

### **5. D√©tection d'Anomalies**
- Optimiser les seuils de d√©tection
- Trouver les meilleurs param√®tres d'isolation forest
- Optimiser les autoencodeurs

---

## ‚≠ê Avantages d'Optuna

### **Compar√© √† Grid Search**
- ‚úÖ **10-100x plus rapide**
- ‚úÖ Trouve de meilleurs r√©sultats
- ‚úÖ Pas besoin de d√©finir une grille

### **Compar√© √† Random Search**
- ‚úÖ **Apprend des essais pr√©c√©dents**
- ‚úÖ Converge plus rapidement
- ‚úÖ R√©sultats plus stables

### **Compar√© √† Hyperopt**
- ‚úÖ API plus simple et intuitive
- ‚úÖ Dashboard interactif int√©gr√©
- ‚úÖ Meilleure documentation
- ‚úÖ D√©veloppement plus actif

### **Compar√© √† Ray Tune**
- ‚úÖ Plus l√©ger et facile √† installer
- ‚úÖ Courbe d'apprentissage plus douce
- ‚úÖ Parfait pour projets moyens

---

## üöÄ D√©marrer avec Optuna

### **Installation**

```bash
pip install optuna
```

### **Premier Script**

```python
import optuna

def objective(trial):
    x = trial.suggest_float('x', -10, 10)
    return (x - 2) ** 2

study = optuna.create_study()
study.optimize(objective, n_trials=100)

print(f"Meilleur x : {study.best_params['x']}")
print(f"Meilleure valeur : {study.best_value}")
```

### **Lancer le Dashboard**

```bash
optuna-dashboard sqlite:///optuna_study.db
```

Ouvrir : http://localhost:8080

---

## üìö Ressources et Documentation

### **Documentation Officielle**
- Site web : https://optuna.org
- Documentation : https://optuna.readthedocs.io
- GitHub : https://github.com/optuna/optuna

### **Tutoriels**
- Tutorial officiel : https://optuna.readthedocs.io/en/stable/tutorial/
- Exemples : https://github.com/optuna/optuna-examples

### **Communaut√©**
- Discord : https://discord.gg/optuna
- Stack Overflow : Tag `optuna`

---

## üéØ Conclusion

**Optuna est l'outil id√©al pour :**
- ‚úÖ Optimiser automatiquement vos mod√®les ML
- ‚úÖ Gagner du temps (10-100x plus rapide que Grid Search)
- ‚úÖ Obtenir de meilleurs r√©sultats
- ‚úÖ Visualiser et comprendre l'optimisation
- ‚úÖ Int√©grer facilement dans vos projets

**Commencez d√®s maintenant avec ce projet !**

---

**Prochaine √©tape : Faire les exercices pratiques !**

