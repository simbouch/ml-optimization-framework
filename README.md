# ğŸ¯ ML Optimization Framework with Optuna

**Educational project demonstrating Optuna's hyperparameter optimization capabilities through interactive examples and comprehensive tutorials**

## ğŸ“ **Educational Purpose**

This project is designed to **teach Optuna** - the automatic hyperparameter optimization framework. Perfect for:
- **Learning Optuna**: From basics to advanced features
- **Team Training**: Share with colleagues to learn optimization
- **Demonstrations**: Show Optuna's capabilities in action
- **Practice**: Hands-on exercises and real examples

### ğŸ¯ **What Your Colleagues Will Learn**
- **Core Concepts**: Studies, trials, samplers, pruners
- **Practical Skills**: Writing objective functions, parameter tuning
- **Advanced Features**: Multi-objective optimization, pruning, visualization
- **Best Practices**: Cross-validation, parameter importance, production tips
- **Real Examples**: Complete working code they can modify and use

## ğŸš€ Quick Start

### **Option 1: Interactive Tutorial Launcher (Recommended)**
```powershell
.\start-tutorial.ps1
```
Choose from:
- ğŸš€ Interactive Dashboard with 6 studies
- ğŸ“– Complete colleague tutorial example
- âš¡ Quick 30-second demo
- ğŸ“‹ Documentation browser

### **Option 2: Direct Dashboard Access**
```bash
docker-compose up -d --build
```
**Then open:** http://localhost:8080

### **Option 3: Colleague Tutorial Example**
```bash
python optuna_colleague_example.py
```
Perfect standalone example to share with team members!

## ğŸ“Š What You'll See

**6 Different Optimization Studies:**
1. **RandomForest Classification (TPE)** - Smart hyperparameter optimization
2. **XGBoost Regression (Random)** - Random sampling comparison  
3. **SVM Classification (Pruning)** - Early stopping demonstration
4. **Multi-objective Optimization** - Accuracy vs Complexity trade-offs
5. **Logistic Regression** - Simple model baseline
6. **RandomForest Regression** - Regression task optimization

**Interactive Dashboard Features:**
- ğŸ“ˆ Optimization history plots
- ğŸ¯ Parameter importance analysis
- ğŸ“Š Parallel coordinate plots
- ğŸ” Trial details and comparisons
- ğŸ“‹ Pareto front visualization (multi-objective)

## ğŸŒŸ About Optuna

**Optuna** is an automatic hyperparameter optimization framework for machine learning. This project demonstrates:

- **TPE Sampling**: Tree-structured Parzen Estimator for intelligent optimization
- **Pruning**: Early stopping of unpromising trials
- **Multi-objective**: Pareto frontier optimization
- **Visualization**: Rich interactive dashboards

## ğŸ”§ Technical Details

**Optimization Techniques:**
- TPE (Tree-structured Parzen Estimator) sampling
- Random sampling for comparison
- Median pruning for early stopping
- Multi-objective optimization with Pareto fronts

**Machine Learning Models:**
- Random Forest (Classification & Regression)
- XGBoost (Regression)
- Support Vector Machine (Classification)
- Logistic Regression (Classification)

**Infrastructure:**
- Docker containerization
- SQLite database storage
- Optuna dashboard visualization
- Automated demo execution

## ğŸ“‹ Requirements

- Docker and Docker Compose
- 2-3 minutes for initial setup

## ğŸ¯ Usage

### Start the Framework
```bash
docker-compose up -d --build
```

### Access Dashboard
Open http://localhost:8080 in your browser

### Stop the Framework
```bash
docker-compose down
```

## ğŸ“š Documentation & Learning

### ğŸ¯ **Start Here: Complete Optuna Tutorial**
- **[ğŸ“– Optuna Tutorial](docs/tutorial.md)** - **Complete guide from basics to advanced**
  - What is Optuna and why use it?
  - Core concepts and terminology
  - Step-by-step examples
  - Hands-on exercises for colleagues
  - Real-world practice examples

### ğŸ“‹ **Project Documentation**
- **[Setup Guide](docs/setup.md)** - Installation and configuration
- **[User Guide](docs/usage.md)** - How to use the dashboard
- **[Study Details](docs/studies.md)** - Explanation of each optimization study
- **[API Reference](docs/api.md)** - Technical implementation details

## ğŸ—ï¸ Project Structure

```
ml-optimization-framework/
â”œâ”€â”€ create_unified_demo.py    # Creates 6 optimization studies
â”œâ”€â”€ docker-compose.yml        # Docker deployment configuration
â”œâ”€â”€ Dockerfile               # Container definition
â”œâ”€â”€ requirements-minimal.txt  # Python dependencies
â”œâ”€â”€ src/                     # Framework source code
â”œâ”€â”€ examples/                # Example optimization scripts
â”œâ”€â”€ docs/                    # Detailed documentation
â””â”€â”€ studies/                 # Generated study databases
```

## ğŸ“ Learning Objectives

This framework demonstrates:
- **TPE vs Random Sampling**: Compare intelligent vs random optimization
- **Pruning Benefits**: Early stopping for computational efficiency  
- **Multi-objective Trade-offs**: Accuracy vs model complexity
- **Real ML Scenarios**: Practical hyperparameter optimization
- **Optuna Best Practices**: Professional optimization workflows

## ğŸ”§ Troubleshooting

**Dashboard not loading?**
- Wait 2-3 minutes for demos to complete
- Check container status: `docker-compose ps`
- View logs: `docker-compose logs`

**Port already in use?**
- Stop existing containers: `docker-compose down`
- Check what's using port 8080: `netstat -an | grep 8080`

## ğŸ“ License

MIT License - See [LICENSE](LICENSE) file for details.

---

**ğŸ¯ Ready to explore Optuna optimization? Start with `docker-compose up -d --build`**
